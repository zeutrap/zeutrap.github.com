---
layout: post
title: "YouTube架构"
description: ""
category: "Architecture"
tags: ["all-time-favorites系列", "一日一架构", "架构", "译文"]
---
{% include JB/setup %}

本文翻译自 HighScalability.com的[YouTube Architecture](http://highscalability.com/youtube-architecture)一文。

YouTube增长很快，现在每日视频的观看次数已经达到1亿次，但其团队人员却只有屈指可数的几人而已。他们是如何将这些视频展示给所有用户的？他们被Google收购后又是如何发展的呢？

##信息源
1. [Google Video](http://video.google.com/videoplay?docid=-6304964351441328559)

##平台
1. Apache
2. Python
3. Linux(Suse)
4. MySQL
5. Psyco，一个动态的 python->C 编译器
6. Lighttpd，在视频方面Apache的替代者

##数字
1. 支持每天超过1亿次的访问量
2. 创建于2005年2月
3. 2006年3月时每天视频观看量达到3千万
4. 2006年7月时每天视频观看量达到1亿
5. 2个系统管理员，2个软件架构师
6. 2个特性开发工程师，2个网络工程师，1个DBA

##解决快速增长的方法
    while (true)
    { 
        identify_and_fix_bottlenecks();
        drink();
        sleep();
        notice_new_bottleneck();
    }
这个迭代每天进行很多次。

##网页服务器
1. 使用NetScalar来进行负载均和静态页面缓存。
2. Apache开启mod_fast_cgi模块。
3. 使用Python应用服务器来处理请求路由。
4. 应用服务器负责与各种数据库和其他信息源通信来获取数据，并格式化html页面；
5. 可以通过增加更多的机器来扩展Web层。
6. Python的代码通常__不是__性能瓶颈，更多的时间是花在了RPC上。
7. Python使得我们可以快速灵活地开发与部署。这对我们面临的竞争很重要；
8. 页面相应时间通常小于100ms。
9. 使用Psyco，这是一种动态的python->c的编译器，它能使用Just-In-Time的编译技术帮助优化内部循环。
10. 对于像加密这种高CPU消耗的需求，我们使用C扩展。
11. 预先生成并缓存渲染代价较高的块。
12. 数据库中使用行级缓存。
13. 完整的Python对象缓存。
14. 一些数据会在计算后发送到每个应用，这样的话它们的值将会被缓存到本地内存中。这是一个**未被充分利用**的策略。最快的缓存是在您的应用服务器里。发送预先计算的数据到每一个服务器并不需要花费太多的时间。你只需要一个代理用来监控数据的变化、预先计算和发送即可。

##视频服务
1. 代价包含带宽、硬件和电力消耗。
2. 每个视频存储在一个迷你集群上。每个视频由多台机器提供服务。
3. 使用集群意味着:  
  ---更多的硬盘意味着更快的速度。  
  ---如果一台机器Down了，其他机器可以替代。  
  ---提供在线备份。  
4. 使用lighttpd作为视频服务器：  
  ---Apache的开销太大。  
  ---使用Epoll来等待多个Fds。  
  ---从单进程切换到多进程可以处理更多的连接数。   
5. 常用的内容迁移到CDN：  
  ---CDN将内容复制到多个地方，这使得内容将可能离用户更近一点，缩短到用户的距离，更容易被用户所访问。  
  ---CDN机器为大部分内容提供基于内存的服务，因为这些内容比较热门，很少有内容需要换进换出内存。  
6. 大量的页面中存在低流行度的视频。
  ---这是长尾效应。有大量的视频只会被播放很少的次数，这会导致磁盘块的随机访问。  
  ---在这种场景下缓存已经不能奏效，所以花钱去偶买更多的缓存是不可取的的。这是非常有趣的事情。当你有长尾时，缓存不再是你性能的救星。  
  ---调整RAID控制器或者注意其他底层的问题可能会有所帮助。  
  ---调整每台机器上的内存保证其大小维持一个合适的状况。  

##视频服务的关键点
1. 保证简单和廉价。  
2. 保证简短的网络路径。不要让内容与用户间存在过多的设备。路由器、交换机和其他设备可能让我们无法到达高负载。  
3. 使用常规硬件。昂贵的硬件将会使得其它方面的代价更昂贵（比如技术支持）。而且你也将更难从网上获得帮助。  
4. 使用简单通用的工具。
5. 处理好随机访问（SATA, 调优）。  

##缩略图服务
1. 令人惊讶的是很难做到有效。  
2. 每一个视频大约有4个缩略图，所以缩略图的量远远超过了视频的量。  
3. 缩略图存储在很少的机器上。  
4. 看到了一些小对象服务面临的问题：
  ---在OS层面有大量的硬盘寻址和inode缓存/页缓存问题。  
  ---碰到了单个目录下文件限制问题。尤其是Ext3文件系统。迁移到一个更多层次的结果。虽然现在2.6内核的改进可能提升Ext3大目录处理能力100倍，但在文件系统中存储大量的文件依旧不是一个好方法。  
  ---每秒有大量的Web页面请求要求显示60个缩略图。  
  ---在这么高的负载下，Apache的表现很差。  
  ---在Apache的前面使用Squid反向代理。这个方法工作了一段时间，但是随着负载的增加性能随之下降，它由一开始的300QPS下降到20。  
  ---尝试使用Lighttped，但是单线程性能有限。多线程模式下又存在每个线程使用独立的缓存的问题。  
  ---在这么多的图片规模下，设置一台新的机器所需要的时间超过24小时。 
  ---重启机器时，缓存需要6-10个小时来预热。  
5. 为了解决这些问题，开始使用Google的BigTable,一个分布式数据存储：
  ---通过将文件组合在一起解决了小文件问题。  
  ---快速、容错。它假设工作在一个不可靠的网络。  
  ---它使用了分布式多级缓存带来了低延迟。这个缓存可以跨站点工作。  
  ---你可以查阅[Google Architecure](http://highscalability.com/google-architecture)，[GoogleTalk Architecture](http://highscalability.com/googletalk-architecture)和[BigTable](http://highscalability.com/tags/bigtable)获取更多关于BigTable的信息。  

##数据库
1. 早期
 ---使用MySQL存储类似于用户、标签和描述等元数据。  
 ---使用10个盘组成一个整体RAID10卷。
 ---使用信用卡来租借硬件。当需要更多的硬件来处理负载时可以在短时间内订购和获得硬件。  
 ---经历了一个很常见的演变过程：单台服务器，到一主机多读从机，然后数据库分区，最后再切片。  
 ---复制延迟是个大问题。主机是运行在强劲机器下的多线程服务器，所以它能够处理大量的工作，而从机通常配置相对差点，而且是单线程，再加上异步复制，所以从机通常会有很明显的延迟。  
 ---更新操作会导致缓存失效，从而会导致磁盘操作。而速度较慢的IO操作也会导致复制变慢。  
 ---使用复制架构需要花更多的钱来提高写性能。  
 ---一种解决方法是通过将数据切分到两个集群来优化速度。其中一个集群是视频观看池，另一个集群是通用的集群。这是因为客户更想观看视频，所以视频观看将获得最多的资源。而社交网络的特性不那么重要，所以它被放置到一个性能相对较差的集群。

2. 最近  
   ---使用数据库分区。  
   ---以用户为基准将数据分成不同的切片。  
   ---连续读写。  
   ---更好地进行本地缓存减少IO操作。  
   ---这些方法减少了30%的硬件。  
   ---复制延迟降低到0。  
   ---可以随意地扩展数据库。  

##数据中心策略
1. 一开始使用主机托管服务。在使用信用卡的前提下它是唯一的出路。  
2. 主机托管服务不能扩展。你不能控制硬件和网络协议。  
3. 于是变成了colocation arrangement。这样就能共自定义所有东西和协商自己的合同。  
4. 使用了5到6个数据中心再加上CDN。  
5. 视频可能从任意数据中心访问，并不是最近匹配或者其他什么规则。如果一个视频足够流行，那么它会进入到CDN中。  
6. 依赖于带宽，而不是真正的延迟。可以来自于任意地方。  
7. 图片的延迟问题比较严重，尤其是当一个页面中存在60个图片时。  
8. 图片被复制到不同的基于BigTable的数据中心，代码中决定谁是最近的。

##学到的东西
1. **拖延时间**。当你在寻找长远的解决方案时，不妨使用创新但有风险的小技巧帮你在短期内解决问题。  
2. **排出优先级**。找到你的核心服务，提高其优先级，在资源和努力上给与倾斜。  
3. **有选择的战斗**。不要害怕将一些基本服务外包。YouTube使用一家CDN来分发最流行的内容。创建自己的网络可能需要太长时间而且也太昂贵。你可能在你的系统里面有类似的机会来实践这一观点。可以看看[软件即服务](http://highscalability.com/tags/saas)来接触更多的观点。  
4. **保持简单**。简单能够让你更快地重构从而使得你能及时响应问题。没有人真正知道简单究竟是什么，但是当你不再畏惧改变的时候，简单也就发生了。
5. **切片**。切片有助于隔离和约束存储、CPU、内存和IO，而不仅仅是获得更好的写性能。  
6. **不断迭代的瓶颈**:
  ---软件：数据库，缓存
  ---操作系统：磁盘IO
  ---硬件：内存，RAID
7. **作为一个团队的成功**。拥有一支懂得整个系统和系统底层的交叉团队。比如有人能够设置打印机，机器，安装网络等等。拥有一支好的团队一切皆有可能。

*译者按: 由于水平有限，文中免不了存在多处错误。还望读者多多指正*。 

